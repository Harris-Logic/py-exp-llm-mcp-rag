#!/usr/bin/env python3
"""
MCPå®¢æˆ·ç«¯ä¸OpenAIé›†æˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•å°†MCPå·¥å…·ä¸OpenAIèŠå¤©åŠŸèƒ½ç»“åˆä½¿ç”¨
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from mcp_client import MCPClient
from chat_openai import AsyncChatOpenAI, ChatOpenAIChatResponse
from utils import pretty

class MCPOpenAIIntegration:
    """MCPå®¢æˆ·ç«¯ä¸OpenAIçš„é›†æˆç±»"""
    
    def __init__(self, mcp_client: MCPClient, model: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ–é›†æˆç±»
        
        Args:
            mcp_client: å·²è¿æ¥çš„MCPå®¢æˆ·ç«¯å®ä¾‹
            model: OpenAIæ¨¡å‹åç§°
        """
        self.mcp_client = mcp_client
        self.model = model
        
        # åˆ›å»ºOpenAIèŠå¤©å®¢æˆ·ç«¯
        self.chat_client = AsyncChatOpenAI(
            model=model,
            tools=mcp_client.get_tools()  # ä½¿ç”¨MCPå·¥å…·
        )
    
    async def process_query(self, query: str) -> str:
        """å¤„ç†æŸ¥è¯¢ï¼Œä½¿ç”¨MCPå·¥å…·å’ŒOpenAI"""
        
        pretty.log_title("Processing Query", "QUERY")
        print(f"ğŸ’¬ User: {query}")
        
        # ä½¿ç”¨OpenAIå¤„ç†æŸ¥è¯¢
        response = await self.chat_client.chat(prompt=query)
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if response.tool_calls:
            pretty.log_title("Tool Calls Detected", "TOOLS")
            
            for tool_call in response.tool_calls:
                tool_name = tool_call.function.name
                tool_args = eval(tool_call.function.arguments)  # å°†å­—ç¬¦ä¸²å‚æ•°è½¬æ¢ä¸ºå­—å…¸
                
                print(f"ğŸ› ï¸  Calling tool: {tool_name}")
                print(f"   Arguments: {tool_args}")
                
                try:
                    # è°ƒç”¨MCPå·¥å…·
                    tool_result = await self.mcp_client.call_tool(tool_name, tool_args)
                    print(f"âœ… Tool result: {tool_result}")
                    
                    # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯ä¸Šä¸‹æ–‡
                    # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç†å·¥å…·ç»“æœå¹¶ç»§ç»­å¯¹è¯
                    
                except Exception as e:
                    print(f"âŒ Tool call failed: {e}")
        
        return response.content

async def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºMCPä¸OpenAIçš„é›†æˆ"""
    
    # åˆ›å»ºMCPå®¢æˆ·ç«¯ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„æœåŠ¡å™¨è·¯å¾„ï¼‰
    mcp_client = MCPClient(
        name="ExampleMCPClient",
        command="python",  # æˆ– "node"
        args=["path/to/your/mcp/server.py"]  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    )
    
    try:
        # è¿æ¥åˆ°MCPæœåŠ¡å™¨
        print("ğŸ”— Connecting to MCP server...")
        await mcp_client.init()
        
        # åˆ›å»ºé›†æˆå®ä¾‹
        integration = MCPOpenAIIntegration(mcp_client)
        
        # ç¤ºä¾‹æŸ¥è¯¢
        queries = [
            "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
            "ä½ èƒ½ä½¿ç”¨å“ªäº›å·¥å…·ï¼Ÿ",
            # æ·»åŠ æ›´å¤šæµ‹è¯•æŸ¥è¯¢
        ]
        
        for query in queries:
            result = await integration.process_query(query)
            print(f"\nğŸ¤– Assistant: {result}")
            print("-" * 50)
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†èµ„æº
        await mcp_client.close()
        print("ğŸ‘‹ Integration demo completed")

if __name__ == "__main__":
    asyncio.run(main())
